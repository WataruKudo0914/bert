{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import modeling\n",
    "import tokenization\n",
    "\n",
    "import run_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = '/home/ubuntu/bert_models/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "vocab_file = '/home/ubuntu/bert_models/uncased_L-12_H-768_A-12/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = run_regressor.ArdProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file,do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = processor.get_test_examples('/home/ubuntu/glue_data/ARD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_features = run_regressor.convert_examples_to_features(test_examples,\n",
    "                                                            max_seq_length=max_seq_length,\n",
    "                                                            tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = []\n",
    "all_input_mask = []\n",
    "all_segment_ids = []\n",
    "all_label_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test_features:\n",
    "    all_input_ids.append(feature.input_ids)\n",
    "    all_input_mask.append(feature.input_mask)\n",
    "    all_segment_ids.append(feature.segment_ids)\n",
    "    all_label_ids.append(feature.label_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tf.constant(all_input_ids[:50])\n",
    "input_mask=tf.constant(all_input_mask[:50])\n",
    "segment_ids=tf.constant(all_segment_ids[:50])\n",
    "label_ids = tf.constant(all_label_ids[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modeling.BertModel(\n",
    "  config=bert_config,\n",
    "  is_training=True,\n",
    "  input_ids=input_ids,\n",
    "  input_mask=input_mask,\n",
    "  token_type_ids=segment_ids,\n",
    "  use_one_hot_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 1\n",
    "is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = model.get_pooled_output()\n",
    "\n",
    "hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "output_weights = tf.get_variable(\n",
    "  \"output_weights\", [1, hidden_size],\n",
    "  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "output_bias = tf.get_variable(\n",
    "  \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    if is_training:\n",
    "        # I.e., 0.1 dropout\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    #probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    #log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    logits = tf.squeeze(logits)\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(label_ids,logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loss_ = loss.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
